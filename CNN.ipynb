{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7gYR9GyCgfgtBNOgMJO4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hungryengineer/ML/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "lLLZc7gcyRm2",
        "outputId": "ea2f323a-a997-493e-9815-0d9dc48d6794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GRU' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1f90b33bb8d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m model = Sequential([\n\u001b[1;32m     42\u001b[0m     \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m ])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GRU' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "\n",
        "# Example corpus of sentences\n",
        "texts = [\n",
        "    \"I love machine learning\",\n",
        "    \"I love deep learning\",\n",
        "    \"machine learning is fun\",\n",
        "    \"deep learning is powerful\",\n",
        "    \"I enjoy learning new things\",\n",
        "    \"learning new skills is valuable\"\n",
        "]\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1  # Add 1 for padding\n",
        "\n",
        "# Prepare sequences for next word prediction\n",
        "sequences = []\n",
        "for line in texts:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        seq = token_list[:i+1]\n",
        "        sequences.append(seq)\n",
        "\n",
        "# Pad sequences and separate inputs and labels\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "# One-hot encode the labels\n",
        "y = np.array(y)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len-1),\n",
        "    SimpleRNN(50),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=300, verbose=0)\n",
        "\n",
        "# Function to predict next word given a seed text\n",
        "def predict_next_word(seed_text):\n",
        "    token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_seq_padded = pad_sequences([token_seq], maxlen=max_len-1, padding='pre')\n",
        "    predicted_probs = model.predict(token_seq_padded, verbose=0)[0]\n",
        "    predicted_word_id = np.argmax(predicted_probs)\n",
        "    for word, idx in word_index.items():\n",
        "        if idx == predicted_word_id:\n",
        "            return word\n",
        "    return \"\"\n",
        "\n",
        "# Example predictions\n",
        "seed_sentences = [\"I love\", \"machine learning\", \"learning new\", \"deep\"]\n",
        "predictions = {seed: predict_next_word(seed) for seed in seed_sentences}\n",
        "predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDIMnawhlV5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06SzWUwllWFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}